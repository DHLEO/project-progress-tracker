<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Progress Tracker</title>
    <link rel="stylesheet" href="styles/main.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>
<body>
    <header>
        <div class="container">
            <h1>A Dynamic Credit Risk Prediction System Based on Federated Learning</h1>
        </div>
    </header>

    <nav>
        <div class="container">
            <ul>
                <li><a href="#overview" class="active">Overview</a></li>
                <li><a href="#team">Team</a></li>
                <li><a href="#updates">Updates</a></li>
                <li><a href="#milestone">Milestone</a></li>
                <li><a href="#deliverables">Deliverables</a></li>
            </ul>
        </div>
    </nav>

    <main>
        <div class="container">
            <section id="overview">
                <h2>Project Overview</h2>
                <div class="card">         
                    <div class="project-stats">
                        <div class="stat">
                            <h3>Start Date</h3>
                            <p>Jan 20, 2025</p>
                        </div>
                        <div class="stat">
                            <h3>End Date</h3>
                            <p>July 31, 2025</p>
                        </div>
                        <div class="stat">
                            <h3>Status</h3>
                            <p class="status in-progress">In Progress</p>
                        </div>
                        <div class="stat">
                            <h3>Completion</h3>
                            <div class="progress-bar">
                                <div class="progress" style="width: 40%;">35%</div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section id="team">
                <h2>Team Members</h2>
                <div class="team-grid">
                    <div class="team-member">
                        <div class="member-photo"></div>
                        <h3>Huang RuiFan</h3>
                        <p class="role">Leader</p>
                        <p class="email">u3638104@connect.hku.hk</p>
                    </div>
                    <div class="team-member">
                        <div class="member-photo"></div>
                        <h3>He Fuzhi</h3>
                        <p class="role">Member</p>
                        <p class="email">u3638289@connect.hku.hk</p>
                    </div>
                    <div class="team-member">
                        <div class="member-photo"></div>
                        <h3>He Yanze</h3>
                        <p class="role">Member</p>
                        <p class="email">u3627468@connect.hku.hk</p>
                    </div>
                    <div class="team-member">
                        <div class="member-photo"></div>
                        <h3>Liu Dahai</h3>
                        <p class="role">Member</p>
                        <p class="email">u3638304@connect.hku.hk</p>
                    </div>
                </div>
            </section>

            <section id="updates">
                <h2>Progress Updates</h2>
                <div class="updates-list">
                    <div class="update-item milestone" data-markdown="<h1>Project Progress Update 2</h1>

<h2>1. Achievements</h2>

<h3>1.1 Data Preprocessing</h3>
<p>In the horizontal federated learning demo, we use the German credit dataset, which contains 
roughly 1,000 records described by 20 input features and a single binary target called kredit. 
In the raw data, about 70% of applicants are labeled as &quot;good&quot; credit (1) and 30% as &quot;bad&quot; 
credit (0). All categorical fields are represented by integer codes, and numeric fields span a 
range of values such as loan amount and duration.</p>

<p>Prior to modeling, categorical features are 
label-encoded and all numeric features are standardized to zero mean and unit variance. The 
full dataset is then split 80/20 into training (≈800 samples) and testing (≈200 samples) sets. 
The training set is further divided equally among three clients (≈266 samples each).</p>

<p>In the vertical federated learning demo, multiple data sources need to possess the following 
core characteristics. Firstly, there should be a high degree of overlap in sample IDs. A large 
number of identical sample identifiers must exist among different data sources, which serves 
as the basis for data alignment and joint modeling. By associating the data from various 
parties through the same sample IDs, collaborative learning can be achieved. Secondly, the 
features should be complementary. The features of each data source describe the samples 
from different dimensions, providing differentiated information. In this way, the data from 
multiple parties can be integrated to enhance the accuracy and generalization ability of the 
model.</p>

<p>Accordingly, in order to verify the feasibility of the algorithm in this round of experiment, we 
adopted the data collected by MIT, which evaluates the credit ratings of users from multiple 
aspects and with a high breadth of features. We divided the data equally into three parts and 
aligned the sample IDs. One of the parts, which contains the personal information of users, 
classifies the users' credit ratings into four categories from high to low. The other two parts of 
the data contain other bank and account features but do not include classification labels. 
Finally, after processing the missing values, dealing with the outliers, labelizing the 
character-type data, and standardizing the data, these three parts of data were put into use in 
this round of experiment.</p>

<h3>1.2 Horizontal Federated Learning Demo</h3>
<p>In this demo, we perform horizontal federated learning on the German Credit dataset, where 
each client holds a different subset of borrower records but uses the same feature set. We 
divide the data randomly into several shards and assign each shard to a Flower NumPyClient. 
Each client trains a small multilayer perceptron locally—three hidden layers of 64, 32, and 16 
units with ReLU activations and a sigmoid output—using a fixed number of mini‑batch 
gradient‑descent epochs (with optional L₂ regularization and gradient clipping). Clients never 
share raw data; they send only their model's parameter updates to the central server.</p>

<p>The Flower server collects these updates and computes a weighted average based on each 
client's number of samples to produce a new global model. To evaluate the benefit of 
collaboration, we also run a separate script that trains the same network architecture in two 
additional modes: entirely centralized (all data pooled) and isolated local (each shard 
individually). We then plot training and validation accuracy over communication rounds for 
all three scenarios. The results show that federated learning converges faster and achieves 
substantially higher validation accuracy than any single‑shard model, while approaching the 
performance of the fully centralized baseline—demonstrating that model quality can be 
greatly improved through collaborative training without ever exchanging private data.</p>

![Federated Learning vs. Centralized vs. Local Training Performance Comparison](images/nn_accuracy_comparison.png)

<h3>1.3 Vertical Federated Learning Demo</h3>
<p>After preprocessing, the data from MIT was divided into three sub-datasets. The data sample 
sizes in different sub-datasets are the same, but the features they contain are different. 
Therefore, the vertical federated learning architecture can be employed. The Secretflow 
architecture has a built-in basic framework for implementing vertical federated learning, 
which enables users to conveniently set up the server side and client sides according to their 
needs. Thus, the three datasets can be allocated to three parties, and one party can be selected 
as the server side. The FedNdArray data structure in Secretflow can directly receive the three 
datasets and automatically distribute them among the three parties.</p>

<p>In terms of model 
construction, Secretflow is highly compatible with the Pytorch architecture, allowing Pytorch 
models to be encapsulated for model training. After the data and model are prepared, a 
vertical federated learning demo can be successfully established. In this experiment, a simple 
MLP model was used, and the experimental results showed that the model trained through 
federated learning using the data from the three parties outperformed the model trained using 
the data from a single party. This outcome is consistent with expectations, as the data from 
the three parties expanded the data features, which is conducive to the learning of the model.</p>

<h2>2. Challenges Faced</h2>

<h3>2.1 Dataset</h3>
<p>We have thus far partitioned our original dataset into three disjoint subsets—either by 
allocating samples across the folds to simulate horizontal federated learning or by dividing 
feature sets among the parties to emulate a vertical federated scenario. We would greatly 
appreciate your guidance on whether there exist more suitable benchmark datasets—perhaps 
those characterized by pronounced statistical heterogeneity or richer feature modalities—or 
alternative approach that you would recommend for strengthening the rigor and realism of 
our federated learning experiments.</p>

<h3>2.2 Innovation</h3>
<p>We would welcome your insight as to whether our federated learning–based credit risk 
scoring project would benefit from one or more substantive methodological innovations to 
elevate its academic and practical impact. If you believe novel contributions are warranted, 
could you recommend specific directions?</p>

<h2>3. Future Plans</h2>

<p>Test on richer, multi‑modal credit datasets—such as those combining tabular borrower 
profiles, transaction sequences, and alternative data sources—while scaling our federation to 
dozens of simulated participants (with hierarchical aggregation to reduce communication 
overhead). Replace simple logistic‑regression baselines with advanced deep architectures (for 
example, transformers to model time‑series transaction behavior and graph neural networks 
to capture borrower–lender networks), and maybe introduce novel methodological 
enhancement to push the state of the art in our federated‑learning framework.</p>">
                        <div class="update-date">May 5, 2025</div>
                        <div class="update-content">
                            <h3>Progress Update 2</h3>
                            <p>Implemented horizontal and vertical federated learning demos using German credit dataset and MIT credit data, with detailed preprocessing and model training workflows. Identified challenges in dataset selection and opportunities for methodological innovation.</p>
                            <div class="view-details"><i class="fas fa-file-alt"></i> View Details</div>
                        </div>
                    </div>
                    <div class="update-item milestone" data-markdown="<h1>Achievements</h1>

<h2>Data Resources</h2>

Four datasets have been found that roughly meet the requirements and need to be used with discretion, not all of them may be usable.
(1) German Credit: Credit data from Germany. The original dataset contains 1000 entries with 20 categorical/symbolic attributes.In this dataset, each entry represents a person who received credit from a bank.Depending on the set of attributes, each person is categorized as either a good credit risk or a bad credit risk.
<br>
(2) Loan data: data on lending transactions from LendingClub (the world's largest peer-to-peer lending platform). Contains 1,800,000 consumer loans originated between 2014 and 2018.
<br>
(3) MIT credit ranking: data collected and designed by MIT to categorize credit rating scores.
P1: very good creditworthiness
P2: Good creditworthiness
P3: Fair credit
P4: Bad credit
These data are collected from financial institutions and contain a variety of characteristics related to customer demographics, credit history, and financial status.
<br>
(4) Real default: defaults that occurred in real scenarios (in fact this is the most granular data but feels the most difficult to process)

<h2>Federal Learning Framework</h2>

In this stage, we have conducted research on Python toolkit frameworks commonly used in federated learning, such as FedLab, Flower, and SecretFlow. All three frameworks are user-friendly, assisting users in building the client side and the server side, and implementing built-in or customized aggregation and comparison methods. We have implemented the official demos of SecretFlow, including horizontal federated learning (HFL) and vertical federated learning (VFL). Whether it is HFL or VFL, the data requires users to perform heterogeneous processing separately. Therefore, the selection, concatenation, and cleaning of the data are of great importance. In SecretFlow, the data will be distributed to different client sides, and the data content is protected through encryption methods to ensure data security. 

<h2>Official Documents:</h2>

(1) SecretFlow: https://www.secretflow.org.cn/en/docs/secretflow/main/tutorial
<br>
(2) Flower: https://flower.ai/docs/framework/main/en/index.html
<br>
(3) FedLab: https://fedlab.readthedocs.io/zh-cn/latest/index.html
<br>

<br>
<br>
<br>

<h1>Challenges</h1>

<h2>Data Challenges</h2>
(1) Data heterogeneity
There are often differences in data characteristics and distribution between datasets from different sources, i.e., data heterogeneity.This data heterogeneity can seriously affect the performance of a federated learning model, making it difficult for the model to achieve good results on data from all participants.
<br>
(2) Communication overhead
Federated learning requires transmission of model parameters among multiple participants.When the dataset size is huge and there are many participants, the frequent transmission of model parameters will generate huge communication overhead, which will also lead to a longer training process.Loan data and Real default two data files will have this problem.
<br>
(3) Inconsistent data formats
Different sources of datasets may use different data formats.Including different features of the different scale between the different features as well as the labeling of the way is not uniform.Failure to convert and standardize the format correctly can result in the data not being loaded smoothly into the federated learning system.
<br>
(4) Failure to ensure data quality

The data quality of different data sources may vary significantly, such as missing data, noisy data, etc.These low-quality data will affect the accuracy of model training and reduce model performance.

<h2>Algorithm Challenges</h2>
Challenges include dealing with semantic ambiguity (e.g., &quot;income&quot; vs. &quot;annual income&quot;), dynamic schema updates, and privacy constraints (e.g., hashing sensitive data).Challenges include resolving ID collisions between organizations, optimizing memory for large datasets, and managing label distribution bias.

<br>
<br>
<br>

<h1>Plans for Upcoming Weeks</h1>

<h2>Data Pre-processing</h2>
(1) Format unification: develop data format conversion tools to unify data sets in different formats into the standard format supported by the federal learning system to ensure that the data can be loaded smoothly.
<br>
(2) Quality enhancement: adopt data cleaning algorithms to remove noisy data and deal with missing values.For example, for numerical data, mean and median can be used to fill in the missing values; for text data, word embedding technology can be used for denoising and patching.
<br>
(3) annotation calibration: establish a unified annotation standard and calibrate annotation data from different sources by manual review and cross-validation to improve the consistency and accuracy of annotation.

<h2>Federated Learning Demo Implementation</h2>
Based on the data resources and federated learning framework research, we plan to implement a federated learning (FL) demo to validate the data preprocessing pipeline, system architecture, and algorithm deployment strategies. We will choose one of the three federated learning frameworks we have evaluated to build the demo environment.
<br> 
<br> 
For this demo, we will use four datasets: German Credit, Loan Data, MIT Credit Ranking, and Real Default. These datasets come from different sources, each with unique characteristics, which can reflect the data heterogeneity typically found in financial settings. Based on the specific properties of each dataset, we will implement either horizontal or vertical federated learning tasks to simulate a multi-party collaborative modeling process.
<br>
<br> 
During the demo, we will perform data cleaning, format unification, feature alignment, and label standardization, then distribute the data to different simulated client nodes for training. We will also incorporate performance evaluation metrics such as Accuracy, AUC, and F1-Score to assess the effectiveness of the model. The goal of this demo is to fully validate the entire federated learning workflow, from data preparation to model training, identify potential technical bottlenecks, and provide a practical foundation for building and optimizing large-scale federated learning systems in the future.
">
                        <div class="update-date">Apr 7, 2025</div>
                        <div class="update-content">
                            <h3>Progress Update 1</h3>
                            <p>Completed dataset selection and federated learning framework evaluation. Identified key challenges and developed strategic plans for data preprocessing and model implementation.</p>
                            <div class="view-details"><i class="fas fa-file-alt"></i> View Details</div>
                        </div>
                    </div>
                </div>
            </section>

            <section id="milestone">
                <h2>Project Milestone</h2>
                <div class="timeline timeline-collapsed">
                    <div class="timeline-item visible">
                        <div class="timeline-dot"></div>
                        <div class="timeline-date">Jan 20 - Mar 24, 2025</div>
                        <div class="timeline-content">
                            <h3>Task 1: Data Schema Mapping & Standardization</h3>
                            <p>Standardized cross-institutional data field mapping files (CSV/JSON) - 15 learning hours</p>
                        </div>
                    </div>
                    <div class="timeline-item visible">
                        <div class="timeline-dot"></div>
                        <div class="timeline-date">Mar 25 - Apr 7, 2025</div>
                        <div class="timeline-content">
                            <h3>Task 2: Horizontal FL Sample Partitioning Tool</h3>
                            <p>Python toolkit for dataset splitting by sample IDs in horizontal FL - 12 learning hours</p>
                        </div>
                    </div>
                    <div class="timeline-item visible">
                        <div class="timeline-dot"></div>
                        <div class="timeline-date">Apr 8 - Apr 20, 2025</div>
                        <div class="timeline-content">
                            <h3>Task 3: Vertical FL Feature Alignment</h3>
                            <p>PySpark-based encrypted feature matching module - 20 learning hours</p>
                        </div>
                    </div>
                    <div class="timeline-item hidden">
                        <div class="timeline-dot"></div>
                        <div class="timeline-date">Apr 21 - May 5, 2025</div>
                        <div class="timeline-content">
                            <h3>Task 4: OPRF-Based PSI Protocol Implementation</h3>
                            <p>Privacy-preserving ID alignment using OPRF - 25 learning hours</p>
                        </div>
                    </div>
                    <div class="timeline-item hidden">
                        <div class="timeline-dot"></div>
                        <div class="timeline-date">May 6 - May 20, 2025</div>
                        <div class="timeline-content">
                            <h3>Task 5: Differential Privacy Noise Injection Module</h3>
                            <p>Implementation of Laplace/Gaussian noise injection for data privacy - 18 learning hours</p>
                        </div>
                    </div>
                    <div class="timeline-item hidden">
                        <div class="timeline-dot"></div>
                        <div class="timeline-date">May 21 - Jun 1, 2025</div>
                        <div class="timeline-content">
                            <h3>Task 6: FedAvg/FedMA/FedProx Algorithm Integration</h3>
                            <p>Implementation and integration of core FL algorithms - 40 learning hours</p>
                        </div>
                    </div>
                    <div class="timeline-item hidden">
                        <div class="timeline-dot"></div>
                        <div class="timeline-date">Jun 2 - Jun 10, 2025</div>
                        <div class="timeline-content">
                            <h3>Task 7: Transformer Model Distillation Framework</h3>
                            <p>Development of model compression toolkit for knowledge transfer - 30 learning hours</p>
                        </div>
                    </div>
                    <div class="timeline-item hidden">
                        <div class="timeline-dot"></div>
                        <div class="timeline-date">Jun 11 - Jun 20, 2025</div>
                        <div class="timeline-content">
                            <h3>Task 8: CAE Label Obfuscation & CAFE Gradient Protection</h3>
                            <p>Implementation of security measures for model protection - 35 learning hours</p>
                        </div>
                    </div>
                    <div class="timeline-item hidden">
                        <div class="timeline-dot"></div>
                        <div class="timeline-date">Jun 21 - Jun 30, 2025</div>
                        <div class="timeline-content">
                            <h3>Task 9: Federated Cross-Validation System Development</h3>
                            <p>Development of validation system with AUC/KS tracking - 25 learning hours</p>
                        </div>
                    </div>
                    <div class="timeline-item hidden">
                        <div class="timeline-dot"></div>
                        <div class="timeline-date">Jul 1 - Jul 7, 2025</div>
                        <div class="timeline-content">
                            <h3>Task 10: Finalize and Evaluation</h3>
                            <p>Comprehensive analysis of model performance and security audits - 20 learning hours</p>
                        </div>
                    </div>
                </div>
                <div class="expand-section">
                    <button class="expand-btn" data-target="timeline">
                        <span class="expand-text">Show More <i class="fas fa-chevron-down"></i></span>
                        <span class="collapse-text">Show Less <i class="fas fa-chevron-up"></i></span>
                    </button>
                </div>
            </section>

            <section id="deliverables">
                <h2>Project Deliverables</h2>
                <div class="deliverables-list deliverables-collapsed">
                    <div class="deliverable-item visible">
                        <h3>Data Mapping Schemas</h3>
                        <p>Standardized cross-institutional data field mapping files (CSV/JSON) for consistent data representation across participating institutions.</p>
                        <div class="deliverable-meta">
                            <span class="deliverable-date">Due: Mar 24, 2025</span>
                        </div>
                    </div>
                    <div class="deliverable-item visible">
                        <h3>Horizontal Partitioning Toolkit</h3>
                        <p>Python toolkit for dataset splitting by sample IDs in horizontal federated learning scenarios.</p>
                        <div class="deliverable-meta">
                            <span class="deliverable-date">Due: Apr 7, 2025</span>
                        </div>
                    </div>
                    <div class="deliverable-item visible">
                        <h3>Vertical Alignment Tool</h3>
                        <p>PySpark-based encrypted feature matching module for vertical federated learning implementation.</p>
                        <div class="deliverable-meta">
                            <span class="deliverable-date">Due: Apr 20, 2025</span>
                        </div>
                    </div>
                    <div class="deliverable-item hidden">
                        <h3>PSI Protocol Library</h3>
                        <p>Python code for privacy-preserving ID alignment using Oblivious Pseudo-Random Function (OPRF).</p>
                        <div class="deliverable-meta">
                            <span class="deliverable-date">Due: May 5, 2025</span>
                        </div>
                    </div>
                    <div class="deliverable-item hidden">
                        <h3>Noise Injection Module</h3>
                        <p>Python module injecting Laplace/Gaussian noise for enhanced data privacy protection.</p>
                        <div class="deliverable-meta">
                            <span class="deliverable-date">Due: May 20, 2025</span>
                        </div>
                    </div>
                    <div class="deliverable-item hidden">
                        <h3>FL Algorithm Suite</h3>
                        <p>Integrated PyTorch implementations of federated learning algorithms including FedAvg, FedMA, and FedProx.</p>
                        <div class="deliverable-meta">
                            <span class="deliverable-date">Due: Jun 1, 2025</span>
                        </div>
                    </div>
                    <div class="deliverable-item hidden">
                        <h3>Distillation Framework</h3>
                        <p>Transformer-based model compression toolkit for efficient knowledge transfer between models.</p>
                        <div class="deliverable-meta">
                            <span class="deliverable-date">Due: Jun 10, 2025</span>
                        </div>
                    </div>
                    <div class="deliverable-item hidden">
                        <h3>Security Toolkit</h3>
                        <p>CAE label obfuscator and CAFE gradient protection system for enhanced model security.</p>
                        <div class="deliverable-meta">
                            <span class="deliverable-date">Due: Jun 20, 2025</span>
                        </div>
                    </div>
                    <div class="deliverable-item hidden">
                        <h3>Validation System</h3>
                        <p>Federated cross-validation tool with AUC/KS tracking capabilities for model performance assessment.</p>
                        <div class="deliverable-meta">
                            <span class="deliverable-date">Due: Jun 30, 2025</span>
                        </div>
                    </div>
                    <div class="deliverable-item hidden">
                        <h3>Final Evaluation</h3>
                        <p>Comprehensive analysis of model performance, security audits, and compliance certification documentation.</p>
                        <div class="deliverable-meta">
                            <span class="deliverable-date">Due: Jul 7, 2025</span>
                        </div>
                    </div>
                </div>
                <div class="expand-section">
                    <button class="expand-btn" data-target="deliverables">
                        <span class="expand-text">Show More <i class="fas fa-chevron-down"></i></span>
                        <span class="collapse-text">Show Less <i class="fas fa-chevron-up"></i></span>
                    </button>
                </div>
            </section>
        </div>
    </main>

    <div id="update-modal" class="modal">
        <div class="modal-content">
            <span class="close-modal">&times;</span>
            <div id="markdown-content" class="markdown-container"></div>
        </div>
    </div>

    <footer>
        <div class="container">
            <p>Last updated: <span id="last-updated">May 5, 2025</span></p>
        </div>
    </footer>

    <script src="js/main.js"></script>
</body>
</html> 
